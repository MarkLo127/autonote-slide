"""
æ¸¬è©¦æ™ºèƒ½æ¨¡å‹é…ç½®ç³»çµ± - åŒ…å«å¤šä¾›æ‡‰å•†æ”¯æ´

é€™å€‹è…³æœ¬ç¤ºç¯„å¦‚ä½•ä½¿ç”¨ LLMSettings.from_model() æ–¹æ³•
ä¾†è‡ªå‹•é¸æ“‡æœ€ä½³çš„æ¨¡å‹é…ç½®ï¼Œä¸¦æ¸¬è©¦æ‰€æœ‰æ”¯æ´çš„ä¾›æ‡‰å•†ã€‚
"""

from app.models.schemas import LLMSettings, MODEL_PROVIDERS

print("=" * 60)
print("æ¸¬è©¦æ¨¡å‹ä¾›æ‡‰å•†é…ç½®")
print("=" * 60)

# åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ä¾›æ‡‰å•†
print("\nğŸ“‹ å¯ç”¨çš„æ¨¡å‹ä¾›æ‡‰å•†:")
for key, provider in MODEL_PROVIDERS.items():
    if key != "custom":
        print(f"  - {provider['name']}: {len(provider['models'])} å€‹æ¨¡å‹")
        print(f"    Base URL: {provider['base_url']}")
        print(f"    API Key Env: {provider['api_key_env']}")
        print(f"    æ¨¡å‹: {', '.join(provider['models'][:3])}{'...' if len(provider['models']) > 3 else ''}")
        print()

print("\n" + "=" * 60)
print("æ¸¬è©¦å„ä¾›æ‡‰å•†çš„æ¨¡å‹é…ç½®")
print("=" * 60)

# æ¸¬è©¦ OpenAI æ¨¡å‹
print("\nğŸ¤– OpenAI æ¨¡å‹é…ç½®")
print("-" * 60)
for model in ["gpt-5.1-2025-11-13", "gpt-5-mini-2025-08-07", "gpt-5-nano-2025-08-07"]:
    settings = LLMSettings.from_model(
        api_key="sk-test-key",
        model=model
    )
    print(f"æ¨¡å‹: {model}")
    print(f"  ä¸¦ç™¼æ•¸: {settings.concurrency}")
    print(f"  æ¯åˆ†é˜è«‹æ±‚æ•¸: {settings.max_requests_per_minute}")
    print(f"  è«‹æ±‚å»¶é²: {settings.request_delay}s")
    print()

# æ¸¬è©¦ Claude æ¨¡å‹
print("ğŸ§  Claude æ¨¡å‹é…ç½®")
print("-" * 60)
for model in MODEL_PROVIDERS["claude"]["models"][:2]:
    settings = LLMSettings.from_model(
        api_key="sk-ant-test-key",
        model=model,
        base_url=MODEL_PROVIDERS["claude"]["base_url"]
    )
    print(f"æ¨¡å‹: {model}")
    print(f"  ä¸¦ç™¼æ•¸: {settings.concurrency}")
    print(f"  æ¯åˆ†é˜è«‹æ±‚æ•¸: {settings.max_requests_per_minute}")
    print(f"  è«‹æ±‚å»¶é²: {settings.request_delay}s")
    print()

# æ¸¬è©¦ Gemini æ¨¡å‹
print("âœ¨ Gemini æ¨¡å‹é…ç½®")
print("-" * 60)
for model in MODEL_PROVIDERS["gemini"]["models"][:2]:
    settings = LLMSettings.from_model(
        api_key="test-gemini-key",
        model=model,
        base_url=MODEL_PROVIDERS["gemini"]["base_url"]
    )
    print(f"æ¨¡å‹: {model}")
    print(f"  ä¸¦ç™¼æ•¸: {settings.concurrency}")
    print(f"  æ¯åˆ†é˜è«‹æ±‚æ•¸: {settings.max_requests_per_minute}")
    print(f"  è«‹æ±‚å»¶é²: {settings.request_delay}s")
    print()

# æ¸¬è©¦ DeepSeek æ¨¡å‹
print("ğŸ”® DeepSeek æ¨¡å‹é…ç½®")
print("-" * 60)
for model in MODEL_PROVIDERS["deepseek"]["models"]:
    settings = LLMSettings.from_model(
        api_key="test-deepseek-key",
        model=model,
        base_url=MODEL_PROVIDERS["deepseek"]["base_url"]
    )
    print(f"æ¨¡å‹: {model}")
    print(f"  ä¸¦ç™¼æ•¸: {settings.concurrency}")
    print(f"  æ¯åˆ†é˜è«‹æ±‚æ•¸: {settings.max_requests_per_minute}")
    print(f"  è«‹æ±‚å»¶é²: {settings.request_delay}s")
    print()

# æ¸¬è©¦ Qwen æ¨¡å‹
print("ğŸŒŸ Qwen æ¨¡å‹é…ç½®")
print("-" * 60)
for model in MODEL_PROVIDERS["qwen"]["models"][:2]:
    settings = LLMSettings.from_model(
        api_key="test-qwen-key",
        model=model,
        base_url=MODEL_PROVIDERS["qwen"]["base_url"]
    )
    print(f"æ¨¡å‹: {model}")
    print(f"  ä¸¦ç™¼æ•¸: {settings.concurrency}")
    print(f"  æ¯åˆ†é˜è«‹æ±‚æ•¸: {settings.max_requests_per_minute}")
    print(f"  è«‹æ±‚å»¶é²: {settings.request_delay}s")
    print()

# æ¸¬è©¦ Grok æ¨¡å‹
print("ğŸš€ Grok æ¨¡å‹é…ç½®")
print("-" * 60)
for model in MODEL_PROVIDERS["grok"]["models"][:3]:
    settings = LLMSettings.from_model(
        api_key="test-grok-key",
        model=model,
        base_url=MODEL_PROVIDERS["grok"]["base_url"]
    )
    print(f"æ¨¡å‹: {model}")
    print(f"  ä¸¦ç™¼æ•¸: {settings.concurrency}")
    print(f"  æ¯åˆ†é˜è«‹æ±‚æ•¸: {settings.max_requests_per_minute}")
    print(f"  è«‹æ±‚å»¶é²: {settings.request_delay}s")
    print()

# æ¸¬è©¦é…ç½®è¦†å¯«
print("\n" + "=" * 60)
print("æ¸¬è©¦é…ç½®è¦†å¯«")
print("=" * 60)
settings_custom = LLMSettings.from_model(
    api_key="sk-test-key",
    model="gpt-5-mini-2025-08-07",
    concurrency=50,  # è¦†å¯«ä¸¦ç™¼æ•¸
    max_retries=10   # è¦†å¯«é‡è©¦æ¬¡æ•¸
)
print(f"æ¨¡å‹: {settings_custom.model}")
print(f"ä¸¦ç™¼æ•¸: {settings_custom.concurrency} (é è¨­: 100, å·²è¦†å¯«ç‚º 50)")
print(f"æœ€å¤§é‡è©¦æ¬¡æ•¸: {settings_custom.max_retries} (é è¨­: 5, å·²è¦†å¯«ç‚º 10)")

print("\nâœ… æ‰€æœ‰é…ç½®æ¸¬è©¦é€šéï¼")
print("=" * 60)
